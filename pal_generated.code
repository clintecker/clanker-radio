<GENERATED-CODE>
1.  **Update `scripts/record_play.py`**: Replace the logging configuration and the `main` function with the versions below. These changes will implement robust, file-based logging and add detailed tracing to pinpoint exactly where execution stops.

<UPDATED_EXISTING_FILE: scripts/record_play.py>
```python
# ... (keep existing imports up to line 15) ...

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from ai_radio.config import config

# --- START: MODIFIED LOGGING CONFIGURATION ---
# Create a dedicated log file to bypass stdio buffering issues from the parent process.
# This is critical for debugging when called from a daemon like Liquidsoap.
log_dir = Path("/tmp/ai_radio_logs")
log_dir.mkdir(exist_ok=True)
log_file = log_dir / "record_play.log"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - PID:%(process)d - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        # Write to a file, which is more reliable than stdout/stderr from a daemon.
        logging.FileHandler(log_file),
        # Also log to console for manual runs.
        logging.StreamHandler(sys.stdout)
    ]
)
# --- END: MODIFIED LOGGING CONFIGURATION ---

logger = logging.getLogger(__name__)


def trigger_export():
    # ... (no changes to this function, keep existing) ...
    """Trigger export_now_playing.py in background (non-blocking).

    Export script has its own lock to prevent simultaneous runs.
    Runs async so we don't block Liquidsoap's on_track callback.
    Failures are logged but don't affect play logging.
    """
    try:
        # Use absolute paths
        export_script = "/srv/ai_radio/scripts/export_now_playing.py"
        venv_python = "/srv/ai_radio/.venv/bin/python"

        # Create log directory for diagnostic output
        log_dir = Path("/tmp/ai_radio_logs")
        log_dir.mkdir(exist_ok=True)
        ts = int(time.time())
        stdout_log = log_dir / f"export_{ts}.out"
        stderr_log = log_dir / f"export_{ts}.err"

        # CRITICAL FIX: Copy environment and augment it, don't replace it
        export_env = os.environ.copy()

        # Safely prepend our src path to PYTHONPATH
        python_path = export_env.get("PYTHONPATH", "")
        src_path = "/srv/ai_radio/src"
        if src_path not in python_path.split(os.pathsep):
            export_env["PYTHONPATH"] = f"{src_path}{os.pathsep}{python_path}".strip(os.pathsep)

        # Write trigger marker for debugging
        marker = f"/tmp/export_triggered_{ts}.marker"
        Path(marker).touch()

        # Start in background with proper logging and environment
        with open(stdout_log, "w") as f_out, open(stderr_log, "w") as f_err:
            subprocess.Popen(
                [venv_python, export_script],
                stdout=f_out,
                stderr=f_err,
                start_new_session=True,
                cwd="/srv/ai_radio",
                env=export_env,
            )

        logger.info(f"Triggered export. Logs: {stdout_log} {stderr_log}")

    except Exception:
        # Use logger.exception for full traceback
        logger.exception("Failed to trigger export")


# --- START: REPLACEMENT main() FUNCTION ---
def main():
    """Entry point for script."""
    # The try/finally block ensures we log the script's end, even on exit.
    try:
        if len(sys.argv) < 2:
            logger.error("Usage: record_play.py <file_path>")
            sys.exit(1)

        file_path = sys.argv[1]
        logger.info(f"Processing file: {file_path}")

        # Look up asset by path to get SHA256 ID
        import sqlite3
        from datetime import datetime, timezone

        conn = sqlite3.connect(config.paths.db_path)
        logger.info("DB connection created.")
        cursor = conn.cursor()

        cursor.execute("SELECT id, kind FROM assets WHERE path = ?", (file_path,))
        row = cursor.fetchone()

        if not row:
            logger.error(f"Asset not found in database: {file_path}")
            logger.error("Make sure all assets are ingested before playback")
            conn.close()
            sys.exit(1)

        asset_id, asset_kind = row
        logger.info(f"Found asset: {asset_id[:16]}... kind={asset_kind}")

        # Write to play_history with SHA256 ID
        now = datetime.now(timezone.utc)
        played_at = now.isoformat()
        hour_bucket = now.replace(minute=0, second=0, microsecond=0).isoformat()

        cursor.execute(
            "INSERT INTO play_history (asset_id, source, played_at, hour_bucket) VALUES (?, ?, ?, ?)",
            (asset_id, asset_kind, played_at, hour_bucket)
        )
        logger.info("Play history INSERT executed.")
        conn.commit()
        logger.info("DB commit successful.")
        conn.close()
        logger.info("DB connection closed.")

        logger.info(f"Recorded play: {asset_id[:16]}... (kind={asset_kind})")

        # Trigger immediate now_playing.json export
        logger.info("Calling trigger_export()...")
        trigger_export()
        logger.info("Returned from trigger_export().")
        sys.exit(0)

    except Exception:
        logger.exception("An unhandled exception occurred in main()")
        sys.exit(1)
    finally:
        # This will run before sys.exit() is fully processed.
        logger.info("--- main() function finished ---")
# --- END: REPLACEMENT main() FUNCTION ---


if __name__ == "__main__":
    logger.info(f"--- Script start. ARGV: {sys.argv} ---")
    main()

```
</UPDATED_EXISTING_FILE>
</GENERATED-CODE>
